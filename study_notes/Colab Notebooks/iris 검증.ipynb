{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"iris 검증.ipynb","provenance":[],"authorship_tag":"ABX9TyORFjiJmsIYQn4R7UjgTRMF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IX8q1Y0MiiB-","executionInfo":{"status":"ok","timestamp":1610940575394,"user_tz":-540,"elapsed":3272,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"91b3f0ac-b0e3-43a6-ebac-0cb71bf79c9d"},"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression as LR\n","import numpy as np\n","import seaborn as sns\n","sns.set(font_scale=1.2)\n","\n","\n","from sklearn import datasets\n","iris = datasets.load_iris()\n","iris.keys()\n","\n","df=pd.DataFrame(iris['data'], columns=iris['feature_names'])\n","df.columns=['sepal_length','sepal_width','petal_length','petal_width']\n","df['Target']=iris['target']\n","\n","df=df.drop_duplicates()\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_data = df.loc[:,'sepal_length':'petal_width']\n","Y_data = df.loc[:, 'Target']\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, \\\n","                                                    test_size=0.2,\n","                                                    shuffle=True,\n","                                                    random_state=20)\n","\n","print(X_train.shape, Y_train.shape)\n","print(X_test.shape, Y_test.shape)\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["(119, 4) (119,)\n","(30, 4) (30,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4OLXhc0ikNL","executionInfo":{"status":"ok","timestamp":1610941059750,"user_tz":-540,"elapsed":760,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"4b7c0249-1eca-4804-e0cc-b74c77bb2136"},"source":["from sklearn.neighbors import KNeighborsClassifier #KNN argorithm\n","knn = KNeighborsClassifier(n_neighbors=5) # k값을 여기에 \n","knn.fit(X_train,Y_train)\n","y_knn_predic = knn.predict(X_test)\n","print(\"prediction:\", y_knn_predic[::1]) # 보여지는 예측값 갯수\n","from sklearn.metrics import accuracy_score\n","knn_acc = accuracy_score(Y_test,y_knn_predic)\n","print(\"Accuracy: %.4f\" % knn_acc) # 정확도 평가 \n","\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["prediction: [0 1 1 2 1 1 2 0 2 0 2 1 2 0 0 2 0 1 2 1 1 2 2 0 2 1 1 0 2 2]\n","Accuracy: 0.9667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ToXFtvYhkWef","executionInfo":{"status":"ok","timestamp":1610941230000,"user_tz":-540,"elapsed":1742,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"2b8de220-394b-4f2f-b485-879c08f034c8"},"source":["from sklearn.svm import SVC #기울기의 한 선에서 가장 멀리떨어진 표본들 구획하기\n","svc=SVC(kernel= 'rbf')      #SVM\n","svc.fit(X_train, Y_train)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n","    max_iter=-1, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvRNYO1HlGST","executionInfo":{"status":"ok","timestamp":1610941380268,"user_tz":-540,"elapsed":894,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"2f46a29e-1a51-419e-b6bb-63caffb9f876"},"source":["y_svc_pred = svc.predict(X_test)\n","print(\"예측값:\",y_svc_pred[:5]) # 예측값 수 \n","svc_acc = accuracy_score(Y_test, y_svc_pred)\n","print(\"Accuarcy:%.4f\" % svc_acc) # 정확도 평가 \n","              "],"execution_count":32,"outputs":[{"output_type":"stream","text":["예측값: [0 1 1 2 1]\n","Accuarcy:1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hCmGBjelPod","executionInfo":{"status":"ok","timestamp":1610941499574,"user_tz":-540,"elapsed":885,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"a6a6355a-c3b0-4fae-f9d4-a0227a9539f0"},"source":["from sklearn.linear_model import LogisticRegression #로지스틱 회귀\n","lrc = LogisticRegression()\n","lrc.fit(X_train, Y_train)"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhvqmoF4mEo8","executionInfo":{"status":"ok","timestamp":1610941676677,"user_tz":-540,"elapsed":1567,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"758c53f9-febe-40ab-c5d2-f0711b1dae3d"},"source":["y_lrc_pred = lrc.predict(X_test)\n","print(\"예측값:\", y_lrc_pred[:5])\n","lrc_acc = accuracy_score(Y_test, y_lrc_pred)\n","print(\"Accuracy:%.4f\" % lrc_acc)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["예측값: [0 1 1 2 1]\n","Accuracy:1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27Gs1sEAmvzT","executionInfo":{"status":"ok","timestamp":1610941776624,"user_tz":-540,"elapsed":1186,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"16c58e89-6697-40d1-8ec4-16d7feb8edcb"},"source":["y_lrc_prob = lrc.predict_proba(X_test)\n","type(y_lrc_prob)"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42rtsKpSnGIr","executionInfo":{"status":"ok","timestamp":1610942639118,"user_tz":-540,"elapsed":980,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"bfee026c-048f-4035-9b22-8a4f613a804f"},"source":["from sklearn.tree import DecisionTreeClassifier\n","dtc= DecisionTreeClassifier(max_depth=3, random_state=20)\n","dtc.fit(X_train, Y_train)"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=3, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=20, splitter='best')"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycMcLRg8qeet","executionInfo":{"status":"ok","timestamp":1610942739520,"user_tz":-540,"elapsed":664,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"48bcf93b-0514-4b9b-9ff9-6dec16974880"},"source":["y_dtc_pred = dtc.predict(X_test)\n","print(\"예측값:\", y_dtc_pred[:5])\n","dtc_acc = accuracy_score(Y_test, y_dtc_pred)\n","print(\"Accuracy:%.4f\" % dtc_acc)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["예측값: [0 1 1 2 1]\n","Accuracy:0.9333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o0gg8TDHq3FS","executionInfo":{"status":"ok","timestamp":1610942960465,"user_tz":-540,"elapsed":1354,"user":{"displayName":"Clear Clufe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_AQV1q2iIMJTJ1Q9aR3KhXA_ch5M-24i9s-T0=s64","userId":"07078249765596298478"}},"outputId":"46be5204-6050-4bfe-c6ec-b1f920e8276f"},"source":["from sklearn.ensemble import VotingClassifier\n","hvc = VotingClassifier(estimators=[('KNN', knn), ('SVM',svc),('DT',dtc)], \n","                      voting='hard')\n","hvc.fit(X_train,Y_train)\n","y_hvc_pred = hvc.predict(X_test)\n","print(\"예측값:\", y_hvc_pred[:5])\n","hvc_acc = accuracy_score(Y_test, y_hvc_pred)\n","print(\"Accuracy:%.4f\" % hvc_acc)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["예측값: [0 1 1 2 1]\n","Accuracy:1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M-Ra8ziCrZ9p"},"source":[""],"execution_count":null,"outputs":[]}]}